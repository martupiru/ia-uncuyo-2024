---
title: tp5-reporte

---

# Reporte Nahman Martina
## Introducci√≥n
Este informe es realizado con el fin de exponer de manera escrita la implementaci√≥n al siguiente problema:
1. Implementar un algoritmo de Hill Climbing para resolver el problema de las N‚àíreinas. 
2. Implementar el algoritmo Simulated Annealing para resolver el problema del ejercicio 1.
3. Implementar un algoritmo gen√©tico para resolver el problema del ejercicio 1. Adem√°s de la
implementaci√≥n en c√≥digo del mismo, se deber√°n incluir detalles respecto a:
a) Definici√≥n de los individuos de la poblaci√≥n.
b) Estrategia de selecci√≥n.
c) Estrategia de reemplazo.
d) Operadores.
## Marco Te√≥rico
### Algoritmos de b√∫squeda local
Son √∫tiles cuando al agente solo le importa el **estado objetivo** y NO la secuencia de estados para llegar al objetivo.Seguimos trabajando bajo un entorno, observable, deterministico y est√°tico. Los mismos no realizan una exploraci√≥n sistem√°tica del espacio de estados. Eval√∫an y modifican un estado o un conjunto reducido de estados ‚Üí se mueven entre estados ‚Äúvecinos‚Äù
### Hill Climbing 
Es un algoritmo iterativo que comienza con una soluci√≥n arbitraria a un problema, luego intenta encontrar una mejor soluci√≥n variando incrementalmente un √∫nico elemento de la soluci√≥n. Si el cambio produce una mejor soluci√≥n, otro cambio incremental se le realiza a la nueva soluci√≥n, repitiendo este proceso hasta que no se puedan encontrar mejoras.
### Simulated Annealing
Es un algoritmo de b√∫squeda metaheur√≠stica para problemas de optimizaci√≥n global; el objetivo general de este tipo de algoritmos es encontrar una buena aproximaci√≥n al valor √≥ptimo de una funci√≥n en un espacio de b√∫squeda grande. Dicho "√≥ptimo global" corresponde a la soluci√≥n del problema de inter√©s para el que no existe un mejor valor. En el caso de que tal problema sea de minimizaci√≥n, el √≥ptimo global ser√° aqu√©l para el cual la funci√≥n objetivo tenga el m√°s peque√±o posible de todos los de su (espacio de b√∫squeda) Por el contrario, para un problema de maxizaci√≥n, el √≥ptimo global es aqu√©l con el valor m√°s alto posible.
### Algoritmos gen√©ticos
Un algoritmo gen√©tico (GA) es un m√©todo de optimizaci√≥n inspirado en los procesos de selecci√≥n natural y evoluci√≥n biol√≥gica. Funciona simulando la evoluci√≥n de soluciones potenciales a un problema, buscando la mejor soluci√≥n posible a trav√©s de iteraciones o generaciones. Los pasos clave son:

1. Poblaci√≥n inicial: Se genera un conjunto de posibles soluciones (individuos).
2. Evaluaci√≥n (fitness): Se mide la calidad de cada soluci√≥n con respecto al problema (funci√≥n de evaluaci√≥n o fitness).
3. Selecci√≥n: Se eligen las mejores soluciones para reproducirse, emulando la supervivencia del m√°s apto.
4. Cruce (crossover): Se combinan dos soluciones para generar una nueva (hijo) con caracter√≠sticas de ambos padres.
5. Mutaci√≥n: Se hacen peque√±os cambios aleatorios en algunos individuos para mantener diversidad gen√©tica.
6. Reemplazo: Las nuevas soluciones reemplazan algunas o todas las soluciones anteriores en la poblaci√≥n.
7. Iteraci√≥n: Se repiten los pasos hasta que se cumple un criterio de parada (como alcanzar una soluci√≥n √≥ptima o llegar a un n√∫mero m√°ximo de generaciones).

El objetivo de un GA es encontrar la soluci√≥n m√°s √≥ptima de manera eficiente, simulando un proceso de evoluci√≥n.

## Dise√±o experimental
### Descripci√≥n experimentos

En este trabajo, se implementaron y compararon tres algoritmos: Hill Climbing (HC), Simulated Annealing (SA) y un Algoritmo Gen√©tico (GA), con el objetivo de resolver el problema de las N-reinas. El objetivo es minimizar el n√∫mero de conflictos entre las reinas en el tablero, representado por la funci√≥n H, que cuenta el n√∫mero de pares de reinas que se atacan entre s√≠.

Los experimentos se realizaron sobre valores de N {4, 8, 10, 12, 15}, con 30 ejecuciones por cada valor de N para obtener estad√≠sticas confiables. Las evaluaciones m√°ximas fueron 1000 por cada ejecuci√≥n de HC y SA, mientras que en GA se ejecutaron 1000 generaciones con una poblaci√≥n de tama√±o 100.

Para Hill Climbing, se generaron vecinos cambiando la posici√≥n de una reina en el tablero y se seleccion√≥ siempre el vecino con el menor H. Si no hab√≠a mejoras, el algoritmo se deten√≠a.

En Simulated Annealing, se utiliz√≥ una funci√≥n exponencial para aceptar soluciones peores con cierta probabilidad controlada por una temperatura decreciente con cada iteraci√≥n. La funci√≥n de aceptaci√≥n fue: 

**P**=e^(‚àíŒîH/T) donde **ŒîH** es el cambio en la funci√≥n H y** ùëá** es la temperatura.

El Algoritmo Gen√©tico utiliz√≥ una poblaci√≥n de tableros (individuos) donde cada individuo representa una posible soluci√≥n al problema. Se implement√≥ un operador de cruce de un punto y mutaci√≥n aleatoria. La selecci√≥n se realiz√≥ mediante ruleta proporcional al fitness inverso de H, y la evaluaci√≥n de generaciones continuaba hasta encontrar una soluci√≥n √≥ptima o alcanzar el n√∫mero m√°ximo de generaciones.

## An√°lisis de datos

Los resultados obtenidos se presentan en las tablas y gr√°ficas adjuntas, comparando los tres algoritmos en t√©rminos de:

1. Porcentaje de √©xito: porcentaje de ejecuciones que alcanzaron una soluci√≥n √≥ptima (H=0).
2. Tiempo de ejecuci√≥n: tiempo promedio en segundos hasta encontrar la soluci√≥n o agotar las evaluaciones.
3. Estados evaluados: cantidad de estados generados durante la b√∫squeda.

**Hill Climbing** mostr√≥ un desempe√±o aceptable para valores peque√±os de N (N=4, N=8), pero su porcentaje de √©xito disminuye dr√°sticamente a medida que N aumenta, debido a que frecuentemente se estanca en √≥ptimos locales. Esto se refleja en que el n√∫mero de estados evaluados es bajo en comparaci√≥n con los otros algoritmos.

**Simulated Annealing** fue m√°s robusto, logrando soluciones √≥ptimas en un mayor porcentaje de ejecuciones, especialmente para valores intermedios de N (N=8, N=10). La funci√≥n de temperatura permiti√≥ escapar de √≥ptimos locales en algunas ejecuciones, pero su eficiencia decrece conforme aumenta N.

El **Algoritmo Gen√©tico** fue el m√°s efectivo en t√©rminos de porcentaje de √©xito, alcanzando soluciones √≥ptimas en la mayor√≠a de las ejecuciones para todos los valores de N. El proceso de selecci√≥n y cruce mantuvo una diversidad en la poblaci√≥n, lo que permiti√≥ explorar m√°s el espacio de soluciones, a costa de un mayor n√∫mero de evaluaciones.

Se observaron distribuciones diferentes en los tiempos de ejecuci√≥n: Hill Climbing fue el *m√°s r√°pido* pero el menos efectivo, mientras que el Algoritmo Gen√©tico fue *m√°s lento* debido a las m√∫ltiples generaciones evaluadas.

Se incluyen boxplots para visualizar la distribuci√≥n de tiempos de ejecuci√≥n y estados evaluados para cada algoritmo y valor de N. Adem√°s, gr√°ficas con respecto a la funcion H.

## Conclusi√≥n
Los experimentos realizados demostraron que, si bien Hill Climbing es un algoritmo r√°pido, no es adecuado para valores grandes de N debido a su tendencia a estancarse en √≥ptimos locales. Simulated Annealing mejora este comportamiento gracias a su capacidad de aceptar soluciones peores bajo ciertas condiciones, pero su efectividad decrece para problemas m√°s complejos.

El Algoritmo Gen√©tico mostr√≥ ser el m√©todo m√°s robusto para resolver el problema de las N-reinas, logrando soluciones √≥ptimas en la mayor√≠a de las ejecuciones, aunque su tiempo de ejecuci√≥n fue mayor debido al proceso de selecci√≥n, cruce y mutaci√≥n.

En resumen, la elecci√≥n del algoritmo depende del tama√±o del problema y de los recursos computacionales disponibles. Para problemas grandes donde se prioriza la exactitud, el Algoritmo Gen√©tico es el m√°s adecuado, mientras que para problemas peque√±os y tiempo limitado, Hill Climbing puede ser suficiente.

